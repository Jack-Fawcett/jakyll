<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Roller, Stephen</author><author>Dinan, Emily</author><author>Goyal, Naman</author><author>Ju, Da</author><author>Williamson, Mary</author><author>Liu, Yinhan</author><author>Xu, Jing</author><author>Ott, Myle</author><author>Shuster, Kurt</author><author>Smith, Eric M.</author><author>Boureau, Y. Lan</author><author>Weston, Jason</author></authors></contributors><titles><title>Recipes for building an open-domain chatbot</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><keywords/><dates><year>2020</year></dates><urls><pdf-urls><url>internal-pdf://Roller et al. - 2020 - Recipes for building an open-domain chatbot.pdf</url></pdf-urls></urls><abstract>Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Cheng, Heng-Tze</author><author>Koc, Levent</author><author>Harmsen, Jeremiah</author><author>Shaked, Tal</author><author>Chandra, Tushar</author><author>Aradhye, Hrishi</author><author>Anderson, Glen</author><author>Corrado, Greg</author><author>Chai, Wei</author><author>Ispir, Mustafa</author><author>Anil, Rohan</author><author>Haque, Zakaria</author><author>Hong, Lichan</author><author>Jain, Vihan</author><author>Liu, Xiaobing</author><author>Shah, Hemal</author></authors></contributors><titles><title>Wide &amp; Deep Learning for Recommender Systems</title><secondary-title>Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</secondary-title></titles><periodical><full-title>Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</full-title></periodical><pages>7-10</pages><keywords><keyword>Recommender Systems</keyword><keyword>Wide &amp; Deep Learning</keyword></keywords><dates><year>2016</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-4795-2</isbn><electronic-resource-num>10.1145/2988450.2988454</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Wide &amp; Deep Learning for Recommender Systems.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/2988450.2988454</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Grbovic, Mihajlo</author><author>Cheng, Haibin</author></authors></contributors><titles><title>Real-time Personalization Using Embeddings for Search Ranking at Airbnb</title><secondary-title>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;#38; Data Mining</secondary-title></titles><periodical><full-title>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;#38; Data Mining</full-title></periodical><pages>311-320</pages><keywords><keyword>personalization</keyword><keyword>search ranking</keyword><keyword>user modeling</keyword></keywords><dates><year>2018</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-5552-0</isbn><electronic-resource-num>10.1145/3219819.3219885</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Real-time Personalization using Embeddings for Search Ranking at Airbnb.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/3219819.3219885</url></web-urls></urls><label>Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Yang</author><author>Feng, Fuli</author><author>Wang, Chenxu</author><author>He, Xiangnan</author><author>Wang, Meng</author><author>Li, Yan</author><author>Zhang, Yongdong</author></authors></contributors><titles><title>How to retrain recommender system? A sequential meta-learning method</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><keywords><keyword>Meta-Learning</keyword><keyword>Model Retraining</keyword><keyword>Recommendation</keyword></keywords><dates><year>2020</year></dates><isbn>9781450380164</isbn><urls><pdf-urls><url>internal-pdf://Zhang et al. - 2020 - How to retrain recommender system A sequential meta-learning method.pdf</url></pdf-urls></urls><abstract>Practical recommender systems need be periodically retrained to refresh the model with new interaction data. To pursue high model fidelity, it is usually desirable to retrain the model on both historical and new data, since it can account for both long-term and short-term user preference. However, a full model retraining could be very time-consuming and memory-costly, especially when the scale of historical data is large. In this work, we study the model retraining mechanism for recommender systems, a topic of high practical values but has been relatively little explored in the research community. Our first belief is that retraining the model on historical data is unnecessary, since the model has been trained on it before Nevertheless, normal training on new data only may easily cause overfitting and forgetting issues, since the new data is of a smaller scale and contains fewer information on long-term user preference To address this dilemma, we propose a new training method, aiming to abandon the historical data during retraining through learning to transfer the past training experience. Specifically, we design a neural network-based transfer component, which transforms the old model to a new model that is tailored for future recommendations To learn the transfer component well, we optimize the “future performance” - i.e., the recommendation accuracy evaluated in the next time period. Our Sequential Meta-Learning (SML) method offers a general training paradigm that is applicable to any differentiable model. We demonstrate SML on matrix factorization and conduct experiments on two real-world datasets. Empirical results show that SML not only achieves significant speed-up, but also outperforms the full model retraining in recommendation accuracy, validating the effectiveness of our proposals. We release our codes at: https //github.com/zyang1580/SML.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Report">10</ref-type><contributors><authors><author>Dueck, Delbert</author><author>Frey, Brendan J</author><author>Dueck, Delbert</author><author>Frey, Brendan J</author></authors></contributors><titles><title>Probabilistic sparse matrix factorization</title><secondary-title>University of Toronto technical report PSI-2004- …</secondary-title></titles><periodical><full-title>University of Toronto technical report PSI-2004- …</full-title></periodical><keywords/><dates><year>2004</year></dates><urls><pdf-urls><url>internal-pdf://Probabilistic Sparse Matrix Factorization.pdf</url></pdf-urls><web-urls><url>http://www.psi.toronto.edu/~psi/pubs/2004/PSI-TR-2004-23.pdf%5Cnhttp://www.psi.toronto.edu/~delbert/docs/Dueck,Frey -- Probabilistic Sparse Matrix Factorization.pdf%5Cnhttp://academic.research.microsoft.com/Publication/3609401/probabilistic-sparse-matrix-</url></web-urls></urls><label>Printed;Read</label><abstract>Many kinds of data can be viewed as consisting of a set of vectors, each of which is a noisy combination of a small number of noisy prototype vec- tors. Physically, these prototype vectors may correspond to different hidden variables that play a role in determining the measured data. For example, a gene's expression is inuenced by the presence of transcription factor pro- teins, and two genes may be activated by overlapping sets of transcription factors. Consequently, the activity of each gene can be explained by the ac- tivities of a small number of transcription factors. This task can be viewed as the problem of factorizing a data matrix, while taking into account hard constraints reecting structural knowledge of the problem and probabilistic relationships between variables that are induced by known uncertainties in the problem. We present soft-decision probabilistic sparse matrix factoriza- tion (PSMF) to better account for uncertainties due to varying levels of noise in the data, varying levels of noise in the prototypes used to explain the data, and uncertainty as to which hidden prototypes are selected to explain each expression vector.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Zheng, Guanjie</author><author>Zhang, Fuzheng</author><author>Zheng, Zihan</author><author>Xiang, Yang</author><author>Yuan, Nicholas Jing</author><author>Xie, Xing</author><author>Li, Zhenhui</author></authors></contributors><titles><title>DRN: A Deep Reinforcement Learning Framework for News Recommendation</title><secondary-title>Proceedings of the 2018 World Wide Web Conference</secondary-title></titles><periodical><full-title>Proceedings of the 2018 World Wide Web Conference</full-title></periodical><pages>167-176</pages><keywords><keyword>deep Q-Learning</keyword><keyword>news recommendation</keyword><keyword>reinforcement learning</keyword></keywords><dates><year>2018</year></dates><pub-location>Republic and Canton of Geneva, Switzerland</pub-location><publisher>International World Wide Web Conferences Steering Committee</publisher><isbn>978-1-4503-5639-8</isbn><electronic-resource-num>10.1145/3178876.3185994</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Deep Reinforcement Learning Framework for News.pdf</url></pdf-urls><web-urls><url>https://doi.org/10.1145/3178876.3185994</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yao, Kaisheng</author><author>Zweig, Geoffrey</author></authors></contributors><titles><title>Sequence-to-sequence neural net models for grapheme-to-phoneme conversion</title><secondary-title>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</secondary-title></titles><periodical><full-title>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</full-title></periodical><pages>3330-3334</pages><volume>2015-Janua</volume><issue>1</issue><keywords><keyword>Grapheme-to-phoneme conversion</keyword><keyword>Neural networks</keyword><keyword>Sequence-to-sequence neural networks</keyword></keywords><dates><year>2015</year></dates><urls><pdf-urls><url>internal-pdf://Yao, Zweig - 2015 - Sequence-to-sequence neural net models for grapheme-to-phoneme conversion.pdf</url></pdf-urls></urls><abstract>Sequence-to-sequence translation methods based on generation with a side-conditioned language model have recently shown promising results in several tasks. In machine translation, models conditioned on source side words have been used to produce target-language text, and in image captioning, models conditioned images have been used to generate caption text. Past work with this approach has focused on large vocabulary tasks, and measured quality in terms of BLEU. In this paper, we explore the applicability of such models to the qualitatively different grapheme-to-phoneme task. Here, the input and output side vocabularies are small, plain n-gram models do well, and credit is only given when the output is exactly correct. We find that the simple side-conditioned generation approach is able to rival the state-of-the-art, and we are able to significantly advance the stat-of-the-art with bi-directional long short-term memory (LSTM) neural networks that use the same alignment information that is used in conventional approaches.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Xie, Xiaolong</author><author>Tan, Wei</author><author>Fong, Liana L</author><author>Liang, Yun</author></authors></contributors><titles><title>CuMF_SGD: Fast and Scalable Matrix Factorization</title><secondary-title>CoRR</secondary-title></titles><periodical><full-title>CoRR</full-title></periodical><volume>abs/1610.0</volume><keywords/><dates><year>2016</year></dates><urls><pdf-urls><url>internal-pdf://CuMF_SGD Fast and Scalable Matrix Factorization.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1610.05838</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Rendle, Steffen</author></authors></contributors><titles><title>Factorization Machines</title><secondary-title>Proceedings of the 2010 IEEE International Conference on Data Mining</secondary-title></titles><periodical><full-title>Proceedings of the 2010 IEEE International Conference on Data Mining</full-title></periodical><pages>995-1000</pages><keywords><keyword>factorization machine</keyword><keyword>sparse data</keyword><keyword>support vector machine</keyword><keyword>tensor factorization</keyword></keywords><dates><year>2010</year></dates><pub-location>Washington, DC, USA</pub-location><publisher>IEEE Computer Society</publisher><isbn>978-0-7695-4256-0</isbn><electronic-resource-num>10.1109/ICDM.2010.127</electronic-resource-num><notes>Mentioned in Amazon Machine Learning / Artificial Intelligence Conference 2020 Recommendation System session.</notes><research-notes>Mentioned in Amazon Machine Learning / Artificial Intelligence Conference 2020 Recommendation System session.</research-notes><urls><pdf-urls><url>internal-pdf://Factorization Machine.pdf</url></pdf-urls><web-urls><url>https://doi.org/10.1109/ICDM.2010.127</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dinan, Emily</author><author>Roller, Stephen</author><author>Shuster, Kurt</author><author>Fan, Angela</author><author>Auli, Michael</author><author>Weston, Jason</author></authors></contributors><titles><title>Wizard of Wiki: Knowledge-powered conversational agents</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><pages>1-18</pages><keywords/><dates><year>2018</year></dates><urls><pdf-urls><url>internal-pdf://Dinan et al. - 2018 - Wizard of Wiki Knowledge-powered conversational agents.pdf</url></pdf-urls></urls><abstract>In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically &quot;generate and hope&quot; generic utterances that can be memorized in the weights of the model when mapping from input utterance( s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mayhew, Stephen</author><author>Bicknell, Klinton</author><author>Brust, Chris</author><author>McDowell, Bill</author><author>Monroe, Will</author><author>Settles, Burr</author></authors></contributors><titles><title>Simultaneous Translation and Paraphrase for Language Education</title></titles><periodical/><pages>232-243</pages><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.18653/v1/2020.ngt-1.28</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Mayhew et al. - 2020 - Simultaneous Translation and Paraphrase for Language Education.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>We present the task of Simultaneous Transla- tion and Paraphrasing for Language Educa- tion (STAPLE). Given a prompt in one lan- guage, the goal is to generate a diverse set of correct translations that language learners are likely to produce. This is motivated by the need to create and maintain large, high-quality sets of acceptable translations for exercises in a language-learning application, and synthe- sizes work spanning machine translation, MT evaluation, automatic paraphrasing, and lan- guage education technology. We developed a novel corpus with unique prop- erties for five languages (Hungarian, Japanese, Korean, Portuguese, and Vietnamese), and re- port on the results of a shared task challenge which attracted 20 teams to solve the task. In our meta-analysis, we focus on three aspects of the resulting systems: external training cor- pus selection, model architecture and training decisions, and decoding and filtering strategies. We find that strong systems start with a large amount of generic training data, and then fine- tune with in-domain data, sampled according to our provided learner response frequencies.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jolliffe, Ian T.</author></authors></contributors><titles><title>A Note on the Use of Principal Components in Regression</title><secondary-title>Applied Statistics</secondary-title></titles><periodical><full-title>Applied Statistics</full-title></periodical><pages>300</pages><volume>31</volume><issue>3</issue><keywords/><dates><year>1982</year></dates><electronic-resource-num>10.2307/2348005</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Jolliffe - 1982 - A Note on the Use of Principal Components in Regression.pdf</url></pdf-urls></urls><label>PCA;Read;Regression</label><abstract>The use of principal components in regression has received a lot of attention in the literature in the past few years, and the topic is now beginning to appear in textbooks. Along with the use of principal component regression there appears to have been a growth in the misconception that the principal components with small eigenvalues will very rarely be of any use in regression. The purpose of this note is to demonstrate that these components can be as important as those with large variance. This is illustrated with four examples, three of which have already appeared in the literature. CR - Copyright &amp;#169; 1982 Royal Statistical Society</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Guo, Huifeng</author><author>Tang, Ruiming</author><author>Ye, Yunming</author><author>Li, Zhenguo</author><author>He, Xiuqiang</author></authors></contributors><titles><title>DeepFM: A Factorization-machine Based Neural Network for CTR Prediction</title><secondary-title>Proceedings of the 26th International Joint Conference on Artificial Intelligence</secondary-title></titles><periodical><full-title>Proceedings of the 26th International Joint Conference on Artificial Intelligence</full-title></periodical><pages>1725-1731</pages><keywords/><dates><year>2017</year></dates><publisher>AAAI Press</publisher><isbn>978-0-9992411-0-3</isbn><electronic-resource-num>10.24963/ijcai.2017/239</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Deep Factorization Machine.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=3172077.3172127</url></web-urls></urls><abstract>Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and highorder feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide and Deep model from Google, DeepFM has a shared input to its &quot;wide&quot; and &quot;deep&quot; parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhou, Li</author><author>Li, Di</author><author>Gao, Jianfeng</author><author>Shum, Heung Yeung</author></authors></contributors><titles><title>The Design and Implementation of XiaoIce, an Empathetic Social Chatbot</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><issue>September 2019</issue><keywords/><dates><year>2018</year></dates><urls><pdf-urls><url>internal-pdf://Zhou et al. - 2018 - The Design and Implementation of XiaoIce, an Empathetic Social Chatbot.pdf</url></pdf-urls></urls><abstract>This paper describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an AI companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient (IQ) and emotional quotient (EQ) in system design, cast human-machine social chat as decision-making over Markov Decision Processes (MDPs), and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large-scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Koren, Yehuda</author></authors></contributors><titles><title>Collaborative filtering with temporal dynamics</title><secondary-title>Communications of the ACM</secondary-title></titles><periodical><full-title>Communications of the ACM</full-title></periodical><pages>89-97</pages><volume>53</volume><issue>4</issue><keywords><keyword>collaborative filtering</keyword><keyword>net-</keyword><keyword>prediction</keyword><keyword>recommender systems</keyword></keywords><dates><year>2010</year></dates><isbn>9781595938343</isbn><electronic-resource-num>10.1145/1721654.1721677</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Koren - 2010 - Collaborative filtering with temporal dynamics.pdf</url></pdf-urls></urls><abstract>Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics is essential for designing recommender systems or general customer preference models. However, this raises unique challenges. Within the ecosystem intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance decay approaches cannot work, as they lose too many signals when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long-term patterns. We show how to model the time changing behavior throughout the life span of the data. Such a model allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie-rating dataset underlying the Netflix Prize contest. Results are encouraging and better than those previously reported on this dataset. In particular, methods described in this paper play a significant role in the solution that won the Netflix contest. © 2010 ACM.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lee, Joonseok</author></authors></contributors><titles><title>Recommendation Systems</title><secondary-title>Big Data and Computational Intelligence in Networking</secondary-title></titles><periodical><full-title>Big Data and Computational Intelligence in Networking</full-title></periodical><pages>227-264</pages><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1201/9781315155678-14</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Recommender Systems Book.pdf</url></pdf-urls></urls><abstract>There is an extensive class of Web applications that involve predicting user responses to options. Such a facility is called a recommendation system. We shall begin this chapter with a survey of the most important examples of these systems. However, to bring the problem into focus, two good examples of recommendation systems are: 1. Offering news articles to on-line newspaper readers, based on a prediction of reader interests. 2. Offering customers of an on-line retailer suggestions about what they might like to buy, based on their past history of purchases and/or product searches. Recommendation systems use a number of different technologies. We can classify these systems into two broad groups. • Content-based systems examine properties of the items recommended. For instance, if a Netflix user has watched many cowboy movies, then recommend a movie classified in the database as having the &quot;cowboy&quot; genre. • Collaborative filtering systems recommend items based on similarity measures between users and/or items. The items recommended to a user are those preferred by similar users. This sort of recommendation system can use the groundwork laid in Chapter 3 on similarity search and Chapter 7 on clustering. However, these technologies by themselves are not sufficient , and there are some new algorithms that have proven effective for recommendation systems. 9.1 A Model for Recommendation Systems In this section we introduce a model for recommendation systems, based on a utility matrix of preferences. We introduce the concept of a &quot;long-tail,&quot; 319</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jin, Rong</author><author>Si, Luo</author></authors></contributors><titles><title>A study of methods for normalizing user ratings in collaborative filtering</title><secondary-title>Proceedings of Sheffield SIGIR - Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</secondary-title></titles><periodical><full-title>Proceedings of Sheffield SIGIR - Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</full-title></periodical><pages>568-569</pages><keywords><keyword>Collaborative filtering</keyword><keyword>Rating normalization</keyword></keywords><dates><year>2004</year></dates><isbn>1581138814</isbn><electronic-resource-num>10.1145/1008992.1009124</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Jin, Si - 2004 - A study of methods for normalizing user ratings in collaborative filtering.pdf</url></pdf-urls></urls><label>Read</label><abstract>The goal of collaborative filtering is to make recommendations for a test user by utilizing the rating information of users who share interests similar to the test user. Because ratings are determined not only by user interests but also the rating habits of users, it is important to normalize ratings of different users to the same scale. In this paper, we compare two different normalization strategies for user ratings, namely the Gaussian normalization method and the decoupling normalization method. Particularly, we incorporated these two rating normalization methods into two collaborative filtering algorithms, and evaluated their effectiveness on the EachMovie dataset. The experiment results have shown that the decoupling method for rating normalization is more effective than the Gaussian normalization method in improving the performance of collaborative filtering algorithms.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pearl, Judea</author></authors></contributors><titles><title>Causal inference in statistics: An overview</title><secondary-title>Statistics Surveys</secondary-title></titles><periodical><full-title>Statistics Surveys</full-title></periodical><pages>96-146</pages><volume>3</volume><issue>September</issue><keywords><keyword>Causal effects</keyword><keyword>Causes of effects</keyword><keyword>Confounding</keyword><keyword>Counterfactuals</keyword><keyword>Graphical methods</keyword><keyword>Mediation</keyword><keyword>Policy evaluation</keyword><keyword>Potential-outcome</keyword><keyword>Structural equationmodels</keyword></keywords><dates><year>2009</year></dates><electronic-resource-num>10.1214/09-SS057</electronic-resource-num><notes>Referenced in Casual Discovery with Reinforcement Learning.</notes><research-notes>Referenced in Casual Discovery with Reinforcement Learning.</research-notes><urls><pdf-urls><url>internal-pdf://Pearl - 2009 - Causal inference in statistics An overview.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>This review presents empirical researcherswith recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interventions, (also called &quot;causal effects&quot; or &quot;policy evaluation&quot;) (2) queries about probabilities of counterfactuals, (including assessment of &quot;regret,&quot; &quot;attribution&quot; or &quot;causes of effects&quot;) and (3) queries about direct and indirect effects (also known as &quot;mediation&quot;). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lunh, H. P.</author></authors></contributors><titles><title>The Automatic Creation of Literature Abstracts</title><secondary-title>IBM Journal of Research Development</secondary-title></titles><periodical><full-title>IBM Journal of Research Development</full-title></periodical><pages>159-165</pages><volume>2</volume><issue>2</issue><keywords><keyword>Lunh</keyword></keywords><dates><year>1958</year></dates><notes>First published attempt at text summarization.
Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</notes><research-notes>First published attempt at text summarization.
Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</research-notes><urls><pdf-urls><url>internal-pdf://Lunh - 1958 - The Automatic Creation of Literature Abstracts.pdf</url></pdf-urls><web-urls><url>http://www.di.ubi.pt/~jpaulo/competence/general/(1958)Luhn.pdf</url></web-urls></urls><label>Printed;Read</label><abstract>Excerpts of technical papers and magazine articles that serve the purposes of conventional abstracts have been created entirely by automatic means. In the exploratory research described, the complete text of an article in machine-readable form i s scanned by a n IBM 704 data-processing machine and analyzed in accordance with a standard program. Statistical information derived from word frequency and distribution is used by the machine to compute a relative measure of significance, first for individual words and then for sentences. Sentences scoring highest in significance are extracted and printed out to become the &quot;auto-abstract.&quot;</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Luo, Yi</author><author>Mesgarani, Nima</author></authors></contributors><titles><title>Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation</title><secondary-title>IEEE/ACM Transactions on Audio Speech and Language Processing</secondary-title></titles><periodical><full-title>IEEE/ACM Transactions on Audio Speech and Language Processing</full-title></periodical><pages>1256-1266</pages><volume>27</volume><issue>8</issue><keywords><keyword>Source separation</keyword><keyword>deep learning</keyword><keyword>real-time</keyword><keyword>single-channel</keyword><keyword>time-domain</keyword></keywords><dates><year>2019</year></dates><electronic-resource-num>10.1109/TASLP.2019.2915167</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Luo, Mesgarani - 2019 - Conv-TasNet Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation.pdf</url></pdf-urls></urls><abstract>Single-channel, speaker-independent speech separation methods have recently seen great progress. However, the accuracy, latency, and computational cost of such methods remain insufficient. The majority of the previous methods have formulated the separation problem through the time-frequency representation of the mixed signal, which has several drawbacks, including the decoupling of the phase and magnitude of the signal, the suboptimality of time-frequency representation for speech separation, and the long latency in calculating the spectrograms. To address these shortcomings, we propose a fully convolutional time-domain audio separation network (Conv-TasNet), a deep learning framework for end-to-end time-domain speech separation. Conv-TasNet uses a linear encoder to generate a representation of the speech waveform optimized for separating individual speakers. Speaker separation is achieved by applying a set of weighting functions (masks) to the encoder output. The modified encoder representations are then inverted back to the waveforms using a linear decoder. The masks are found using a temporal convolutional network consisting of stacked one-dimensional dilated convolutional blocks, which allows the network to model the long-term dependencies of the speech signal while maintaining a small model size. The proposed Conv-TasNet system significantly outperforms previous time-frequency masking methods in separating two- and three-speaker mixtures. Additionally, Conv-TasNet surpasses several ideal time-frequency magnitude masks in two-speaker speech separation as evaluated by both objective distortion measures and subjective quality assessment by human listeners. Finally, Conv-TasNet has a significantly smaller model size and a shorter minimum latency, making it a suitable solution for both offline and real-time speech separation applications. This study, therefore, represents a major step toward the realization of speech separation systems for real-world speech processing technologies.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zeng, Zexian</author><author>Jiang, Xia</author><author>Neapolitan, Richard</author></authors></contributors><titles><title>Discovering causal interactions using Bayesian network scoring and information gain</title><secondary-title>BMC Bioinformatics</secondary-title></titles><periodical><full-title>BMC Bioinformatics</full-title></periodical><pages>1-14</pages><volume>17</volume><issue>1</issue><keywords><keyword>Bayesian network</keyword><keyword>Breast cancer survival</keyword><keyword>Cause</keyword><keyword>Epistasis</keyword><keyword>Information gain</keyword><keyword>Interaction</keyword><keyword>Low-dimensional</keyword></keywords><dates><year>2016</year></dates><publisher>BMC Bioinformatics</publisher><electronic-resource-num>10.1186/s12859-016-1084-8</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Zeng, Jiang, Neapolitan - 2016 - Discovering causal interactions using Bayesian network scoring and information gain.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1186/s12859-016-1084-8</url></web-urls></urls><abstract>Background: The problem of learning causal influences from data has recently attracted much attention. Standard statistical methods can have difficulty learning discrete causes, which interacting to affect a target, because the assumptions in these methods often do not model discrete causal relationships well. An important task then is to learn such interactions from data. Motivated by the problem of learning epistatic interactions from datasets developed in genome-wide association studies (GWAS), researchers conceived new methods for learning discrete interactions. However, many of these methods do not differentiate a model representing a true interaction from a model representing non-interacting causes with strong individual affects. The recent algorithm MBS-IGain addresses this difficulty by using Bayesian network learning and information gain to discover interactions from high-dimensional datasets. However, MBS-IGain requires marginal effects to detect interactions containing more than two causes. If the dataset is not high-dimensional, we can avoid this shortcoming by doing an exhaustive search. Results: We develop Exhaustive-IGain, which is like MBS-IGain but does an exhaustive search. We compare the performance of Exhaustive-IGain to MBS-IGain using low-dimensional simulated datasets based on interactions with marginal effects and ones based on interactions without marginal effects. Their performance is similar on the datasets based on marginal effects. However, Exhaustive-IGain compellingly outperforms MBS-IGain on the datasets based on 3 and 4-cause interactions without marginal effects. We apply Exhaustive-IGain to investigate how clinical variables interact to affect breast cancer survival, and obtain results that agree with judgements of a breast cancer oncologist. Conclusions: We conclude that the combined use of information gain and Bayesian network scoring enables us to discover higher order interactions with no marginal effects if we perform an exhaustive search. We further conclude that Exhaustive-IGain can be effective when applied to real data.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lynch, Tiina</author><author>Ghergulescu, Ioana</author></authors></contributors><titles><title>An Evaluation Framework for Adaptive and Intelligent Tutoring Systems</title></titles><periodical/><pages>1385-1390</pages><keywords><keyword>Designing, Developing, and Assessing E-Learning</keyword></keywords><dates><year>2016</year></dates><notes>Adaptemy research suggested by Tim Hesse.</notes><research-notes>Adaptemy research suggested by Tim Hesse.</research-notes><urls><pdf-urls><url>internal-pdf://Lynch, Ghergulescu - 2016 - An Evaluation Framework for Adaptive and Intelligent Tutoring Systems.pdf</url></pdf-urls></urls><abstract>Evaluation frameworks for adaptive and intelligent tutoring systems have largely focused on their prediction power or user experience. However, neither subjective or objective method alone is enough to assess all the properties of any given system, including effectiveness, efficiency and accuracy. This paper proposes an evaluation framework as well as evaluation recommendations for adaptive and intelligent learning systems. The evaluation framework incorporates objective and subjective measures in terms of learning effectiveness, learning efficiency, system accuracy, satisfaction, ease of use and learner engagement.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Salakhutdinov, Ruslan</author><author>Mnih, Andriy</author></authors></contributors><titles><title>Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo</title><secondary-title>25th International Conference on Machine Learning (ICML- 2008)</secondary-title></titles><periodical><full-title>25th International Conference on Machine Learning (ICML- 2008)</full-title></periodical><keywords/><dates><year>2008</year></dates><urls><pdf-urls><url>internal-pdf://Salakhutdinov, Mnih - 2008 - Bayesian Probabilistic Matrix Factorization using Markov Chain Monte Carlo.pdf</url></pdf-urls></urls><label>Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Buza, Antal</author><author>Kis, Piroska B</author></authors></contributors><titles><title>Instability of Matrix Factorization Used in Recommender Systems</title><secondary-title>Annales Univ. Sci. Budapest, Sect. Comp.</secondary-title></titles><periodical><full-title>Annales Univ. Sci. Budapest, Sect. Comp.</full-title></periodical><pages>83-91</pages><volume>42</volume><keywords><keyword>15a23</keyword><keyword>2010 mathematics subject classification</keyword><keyword>49k40</keyword><keyword>and phrases</keyword><keyword>factorization of matrices</keyword><keyword>recommender system</keyword><keyword>stability</keyword></keywords><dates><year>2014</year></dates><urls><pdf-urls><url>internal-pdf://Instability of Matrix Factorization Used in Recommender Systems.pdf</url></pdf-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bao, Siqi</author><author>He, Huang</author><author>Wang, Fan</author><author>Wu, Hua</author><author>Wang, Haifeng</author><author>Wu, Wenquan</author><author>Guo, Zhen</author><author>Liu, Zhibin</author><author>Xu, Xinchao</author></authors></contributors><titles><title>PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><keywords/><dates><year>2020</year></dates><urls><pdf-urls><url>internal-pdf://Bao et al. - 2020 - PLATO-2 Towards Building an Open-Domain Chatbot via Curriculum Learning.pdf</url></pdf-urls></urls><abstract>To build a high-quality open-domain chatbot, we introduce the effective training process of PLATO-2 via curriculum learning. There are two stages involved in the learning process. In the first stage, a coarse-grained generation model is trained to learn response generation under the simplified framework of one-to-one mapping. In the second stage, a fine-grained generation model and an evaluation model are further trained to learn diverse response generation and response coherence estimation, respectively. PLATO-2 was trained on both Chinese and English data, whose effectiveness and superiority are verified through comprehensive evaluations, achieving new state-ofthe-art results.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abdollahi, Behnoush</author><author>Nasraoui, Olfa</author></authors></contributors><titles><title>Explainable Matrix Factorization for Collaborative Filtering</title></titles><periodical/><pages>5-6</pages><keywords><keyword>cf</keyword><keyword>collaborative filtering</keyword><keyword>explanations</keyword><keyword>matrix factorization</keyword><keyword>mf</keyword><keyword>recommender sys-</keyword><keyword>tems</keyword></keywords><dates><year>2016</year></dates><isbn>9781450341448</isbn><electronic-resource-num>10.1145/2872518.2889405</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Abdollahi, Nasraoui - 2016 - Explainable Matrix Factorization for Collaborative Filtering.pdf</url></pdf-urls></urls><label>Read</label><abstract>Explanations have been shown to increase the user's trust in recommendations in addition to providing other benefits such as scrutability, which is the ability to verify the va-lidity of recommendations. Most explanation methods are designed for classical neighborhood-based Collaborative Fil-tering (CF) or rule-based methods. For the state of the art Matrix Factorization (MF) recommender systems, recent ex-planation methods, require an additional data source, such as item content data, in addition to rating data. In this paper, we address the case where no such additional data is available and propose a new Explainable Matrix Factor-ization (EMF) technique that computes an accurate top-n recommendation list of items that are explainable. We also introduce new explanation quality metrics, that we call Mean Explainability Precision (MEP) and Mean Explain-ability Recall (MER).</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Devlin, Jacob</author><author>Chang, Ming-Wei</author><author>Lee, Kenton</author><author>Toutanova, Kristina</author></authors></contributors><titles><title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title></titles><periodical/><issue>Mlm</issue><keywords/><dates><year>2018</year></dates><urls><pdf-urls><url>internal-pdf://Google BERT.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1810.04805</url></web-urls></urls><label>Printed</label><abstract>We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Finn, Chelsea</author><author>Abbeel, Pieter</author><author>Levine, Sergey</author></authors></contributors><titles><title>Model-agnostic Meta-learning for Fast Adaptation of Deep Networks</title><secondary-title>Proceedings of the 34th International Conference on Machine Learning - Volume 70</secondary-title></titles><periodical><full-title>Proceedings of the 34th International Conference on Machine Learning - Volume 70</full-title></periodical><pages>1126-1135</pages><keywords/><dates><year>2017</year></dates><publisher>JMLR.org</publisher><urls><pdf-urls><url>internal-pdf://Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=3305381.3305498</url></web-urls></urls><label>Printed</label><abstract>We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is com- patible with any model trained with gradient de- scent and applicable to a variety of different learning problems, including classification, re- gression, and reinforcement learning. The goal of meta-learning is to train a model on a vari- ety of learning tasks, such that it can solve new learning tasks using only a small number of train- ing samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few- shot image classification benchmarks, produces good results on few-shot regression, and acceler- ates fine-tuning for policy gradient reinforcement learning with neural network policies.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fawcett, V. A.</author><author>Alexander, D. M.</author><author>Rosario, D. J.</author><author>Klindt, L.</author><author>Fotopoulou, S.</author><author>Lusso, E.</author><author>Morabito, L.</author><author>Rivera, G. Calistro</author></authors></contributors><titles><title>Fundamental differences in the radio properties of red and blue quasars: enhanced compact AGN emission in red quasars</title></titles><periodical/><pages>1-16</pages><volume>16</volume><issue>April</issue><keywords/><dates><year>2020</year></dates><urls><pdf-urls><url>internal-pdf://Fawcett et al. - 2020 - Fundamental differences in the radio properties of red and blue quasars enhanced compact AGN emission in red qua.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>We have recently used the Faint Images of the Radio Sky at Twenty-centimeters (FIRST) survey to show that red quasars have fundamentally different radio properties to typical blue quasars: a significant (factor ≈ 3) enhancement in the radio-detection fraction, which arises from systems around the radio-quiet threshold with compact (&lt; 5??) radio morphologies. To gain greater insight into these physical differences, here we use the DR14 Sloan Digital Sky Survey (SDSS) and more sensitive, higher resolution radio data from the Very Large Array (VLA) Stripe 82 (S82) and VLA-COSMOS 3 GHz (C3GHz) surveys. With the S82 data, we perform morphological analyses at a resolution and depth three times that of the FIRST radio survey, and confirm an enhancement in radio-faint and compact red quasars over typical quasars; we now also find tentative evidence for an enhancement in red quasars with slightly extended radio structures (16–43 kpc at z = 1.5). These analyses are complemented by C3GHz, which is deep enough to detect radio emission from star-formation processes. From our data we find that the radio enhancement from red quasars is due to AGN activity on compact scales (?43 kpc) for radio-intermediate–radio-quiet sources (−5 &lt; R &lt;−3.4, where R = L1.4GHz/L6µm), which decreases at R &lt;−5 as the radio emission from star-formation starts to dilute the AGN component. Overall our results argue against a simple orientation scenario and are consistent with red quasars representing a younger, earlier phase in the overall evolution of quasars. Key</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Muhan</author><author>Chen, Yixin</author></authors></contributors><titles><title>Inductive Matrix Completion Based on Graph Neural Networks</title></titles><periodical/><pages>1-14</pages><issue>Imc</issue><keywords/><dates><year>2019</year></dates><urls><pdf-urls><url>internal-pdf://Zhang, Chen - 2019 - Inductive Matrix Completion Based on Graph Neural Networks.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1904.12058</url></web-urls></urls><label>Read</label><abstract>We propose an inductive matrix completion model without using side information. By factorizing the (rating) matrix into the product of low-dimensional latent embeddings of rows (users) and columns (items), a majority of existing matrix completion methods are transductive, since the learned embeddings cannot generalize to unseen rows/columns or to new matrices. To make matrix completion inductive, most previous works use content (side information), such as user's age or movie's genre, to make predictions. However, high-quality content is not always available, and can be hard to extract. Under the extreme setting where not any side information is available other than the matrix to complete, can we still learn an inductive matrix completion model? In this paper, we propose an Inductive Graph-based Matrix Completion (IGMC) model to address this problem. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps these subgraphs to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive -- it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks. Our transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Our work demonstrates that: 1) it is possible to train inductive matrix completion models without using side information while achieving similar or better performances than state-of-the-art transductive methods; 2) local graph patterns around a (user, item) pair are effective predictors of the rating this user gives to the item; and 3) Long-range dependencies might not be necessary for modeling recommender systems.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Chen, Qiwei</author><author>Zhao, Huan</author><author>Li, Wei</author><author>Huang, Pipei</author><author>Ou, Wenwu</author></authors></contributors><titles><title>Behavior Sequence Transformer for E-commerce Recommendation in Alibaba</title></titles><periodical/><keywords/><dates><year>2019</year></dates><urls><pdf-urls><url>internal-pdf://Behavior Sequence Transformer for E-commerce Recommendation in Alibaba.pdf</url></pdf-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cui, Can</author><author>Hu, Mengqi</author><author>Weir, Jeffery D.</author><author>Wu, Teresa</author></authors></contributors><titles><title>A recommendation system for meta-modeling: A meta-learning based approach</title><secondary-title>Expert Systems with Applications</secondary-title></titles><periodical><full-title>Expert Systems with Applications</full-title></periodical><pages>33-44</pages><volume>46</volume><keywords><keyword>Algorithm selection</keyword><keyword>Feature reduction</keyword><keyword>Meta-learning</keyword><keyword>Meta-model</keyword><keyword>Recommendation system</keyword><keyword>Simulation</keyword></keywords><dates><year>2016</year></dates><electronic-resource-num>10.1016/j.eswa.2015.10.021</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Cui et al. - 2016 - A recommendation system for meta-modeling A meta-learning based approach.pdf</url></pdf-urls></urls><abstract>Various meta-modeling techniques have been developed to replace computationally expensive simulation models. The performance of these meta-modeling techniques on different models is varied which makes existing model selection/recommendation approaches (e.g., trial-and-error, ensemble) problematic. To address these research gaps, we propose a general meta-modeling recommendation system using meta-learning which can automate the meta-modeling recommendation process by intelligently adapting the learning bias to problem characterizations. The proposed intelligent recommendation system includes four modules: (1) problem module, (2) meta-feature module which includes a comprehensive set of meta-features to characterize the geometrical properties of problems, (3) meta-learner module which compares the performance of instance-based and model-based learning approaches for optimal framework design, and (4) performance evaluation module which introduces two criteria, Spearman's ranking correlation coefficient and hit ratio, to evaluate the system on the accuracy of model ranking prediction and the precision of the best model recommendation, respectively. To further improve the performance of meta-learning for meta-modeling recommendation, different types of feature reduction techniques, including singular value decomposition, stepwise regression and ReliefF, are studied. Experiments show that our proposed framework is able to achieve 94% correlation on model rankings, and a 91% hit ratio on best model recommendation. Moreover, the computational cost of meta-modeling recommendation is significantly reduced from an order of minutes to seconds compared to traditional trial-and-error and ensemble process. The proposed framework can significantly advance the research in meta-modeling recommendation, and can be applied for data-driven system modeling.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bobadilla, J.</author><author>Ortega, F.</author><author>Hernando, A.</author><author>Gutiérrez, A.</author></authors></contributors><titles><title>Recommender Systems Survey</title><secondary-title>Knowledge-Based Systems</secondary-title></titles><periodical><full-title>Knowledge-Based Systems</full-title></periodical><pages>109-132</pages><volume>46</volume><keywords><keyword>Cold-start</keyword><keyword>Collaborative filtering</keyword><keyword>Evaluation metrics</keyword><keyword>Hybrid</keyword><keyword>Internet of things</keyword><keyword>Prediction</keyword><keyword>Recommendation</keyword><keyword>Recommender systems</keyword><keyword>Similarity measures</keyword><keyword>Social</keyword></keywords><dates><year>2013</year></dates><pub-location>Amsterdam, The Netherlands, The Netherlands</pub-location><publisher>Elsevier B.V.</publisher><electronic-resource-num>10.1016/j.knosys.2013.03.012</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Recommender Systems - Bobadilla - 2013.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1016/j.knosys.2013.03.012</url></web-urls></urls><abstract>Recommender systems have developed in parallel with the web. They were initially based on demographic, content-based and collaborative filtering. Currently, these systems are incorporating social information. In the future, they will use implicit, local and personal information from the Internet of things. This article provides an overview of recommender systems as well as collaborative filtering methods and algorithms; it also explains their evolution, provides an original classification for these systems, identifies areas of future implementation and develops certain areas selected for past, present or future importance. © 2013 Elsevier B.V. All rights reserved.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Fujita, André</author><author>Gomes, Luciana Rodrigues</author><author>Sato, João Ricardo</author><author>Yamaguchi, Rui</author><author>Thomaz, Carlos Eduardo</author><author>Sogayar, Mari Cleide</author><author>Miyano, Satoru</author></authors></contributors><titles><title>Multivariate gene expression analysis reveals functional connectivity changes between normal/tumoral prostates</title><secondary-title>BMC Systems Biology</secondary-title></titles><periodical><full-title>BMC Systems Biology</full-title></periodical><pages>1-14</pages><volume>2</volume><keywords/><dates><year>2008</year></dates><accession-num>19055846</accession-num><electronic-resource-num>10.1186/1752-0509-2-106</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Fujita et al. - 2008 - Multivariate gene expression analysis reveals functional connectivity changes between normaltumoral prostates.pdf</url></pdf-urls></urls><abstract>Background: Prostate cancer is a leading cause of death in the male population, therefore, a comprehensive study about the genes and the molecular networks involved in the tumoral prostate process becomes necessary. In order to understand the biological process behind potential biomarkers, we have analyzed a set of 57 cDNA microarrays containing ∼25,000 genes. Results: Principal Component Analysis (PCA) combined with the Maximum-entropy Linear Discriminant Analysis (MLDA) were applied in order to identify genes with the most discriminative information between normal and tumoral prostatic tissues. Data analysis was carried out using three different approaches, namely: (i) differences in gene expression levels between normal and tumoral conditions from an univariate point of view; (ii) in a multivariate fashion using MLDA; and (iii) with a dependence network approach. Our results show that malignant transformation in the prostatic tissue is more related to functional connectivity changes in their dependence networks than to differential gene expression. The MYLK, KLK2, KLK3, HAN11, LTF, CSRP1 and TGM4 genes presented significant changes in their functional connectivity between normal and tumoral conditions and were also classified as the top seven most informative genes for the prostate cancer genesis process by our discriminant analysis. Moreover, among the identified genes we found classically known biomarkers and genes which are closely related to tumoral prostate, such as KLK3 and KLK2 and several other potential ones. Conclusion: We have demonstrated that changes in functional connectivity may be implicit in the biological process which renders some genes more informative to discriminate between normal and tumoral conditions. Using the proposed method, namely, MLDA, in order to analyze the multivariate characteristic of genes, it was possible to capture the changes in dependence networks which are related to cell transformation. © 2008 Fujita et al; licensee BioMed Central Ltd.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Elvir, Miguel</author><author>Gonzalez, Avelino J.</author><author>Walls, Christopher</author><author>Wilder, Bryan</author></authors></contributors><titles><title>Remembering a Conversation - A Conversational Memory Architecture for Embodied Conversational Agents</title><secondary-title>Journal of Intelligent Systems</secondary-title></titles><periodical><full-title>Journal of Intelligent Systems</full-title></periodical><pages>1-21</pages><volume>26</volume><issue>1</issue><keywords><keyword>Chatbots</keyword><keyword>Embodied Conversational Agents</keyword><keyword>chatterbots</keyword><keyword>conversational agents</keyword><keyword>conversational memory</keyword><keyword>episodic memory</keyword><keyword>episodic memory architecture</keyword></keywords><dates><year>2017</year></dates><electronic-resource-num>10.1515/jisys-2015-0094</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Elvir et al. - 2017 - Remembering a Conversation - A Conversational Memory Architecture for Embodied Conversational Agents.pdf</url></pdf-urls></urls><abstract>This paper addresses the role of conversational memory in Embodied Conversational Agents (ECAs). It describes an investigation into developing such a memory architecture and integrating it into an ECA. ECAs are virtual agents whose purpose is to engage in conversations with human users, typically through natural language speech. While several works in the literature seek to produce viable ECA dialog architectures, only a few authors have addressed the episodic memory architectures in conversational agents and their role in enhancing their intelligence. In this work, we propose, implement, and test a unified episodic memory architecture for ECAs. We describe a process that determines the prevalent contexts in the conversations obtained from the interactions. The process presented demonstrates the use of multiple techniques to extract and store relevant snippets from long conversations, most of whose contents are unremarkable and need not be remembered. The mechanisms used to store, retrieve, and recall episodes from previous conversations are presented and discussed. Finally, we test our episodic memory architecture to assess its effectiveness. The results indicate moderate success in some aspects of the memory-enhanced ECAs, as well as some work still to be done in other aspects.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Padmakumar, Aishwarya</author><author>Saran, Akanksha</author></authors></contributors><titles><title>Unsupervised Text Summarization Using Sentence Embeddings</title></titles><periodical/><keywords/><dates><year>2016</year></dates><urls><pdf-urls><url>internal-pdf://Padmakumar, Saran - 2016 - Unsupervised Text Summarization Using Sentence Embeddings.pdf</url></pdf-urls></urls><label>NLP;Printed;Read;Unsupervided</label><abstract>Dense vector representations of words, and more recently , sentences, have been shown to improve performance in a number of NLP tasks. We propose a method to perform unsupervised extractive and abstractive text summarization using sentence embeddings. We compare multiple variants of our systems on two datasets, show substantially improved performance over a simple baseline, and performance approaching a competitive baseline.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Ganesan, Kavita</author><author>Zhai, Cheng Xiang</author><author>Han, Jiawei</author></authors></contributors><titles><title>Opinosis: A graph-based approach to abstractive summarization of highly redundant opinions</title><secondary-title>Coling 2010 - 23rd International Conference on Computational Linguistics, Proceedings of the Conference</secondary-title></titles><periodical><full-title>Coling 2010 - 23rd International Conference on Computational Linguistics, Proceedings of the Conference</full-title></periodical><pages>340-348</pages><volume>2</volume><issue>August</issue><keywords/><dates><year>2010</year></dates><notes>Graph based text summarization. Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</notes><research-notes>Graph based text summarization. Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</research-notes><urls><pdf-urls><url>internal-pdf://Ganesan, Zhai, Han - 2010 - Opinosis A graph-based approach to abstractive summarization of highly redundant opinions.pdf</url></pdf-urls></urls><label>NLP;Printed;Read</label><abstract>We present a novel graph-based summarization framework (Opinosis) that generates concise abstractive summaries of highly redundant opinions. Evaluation results on summarizing user reviews show that Opinosis summaries have better agreement with human summaries compared to the baseline extractive method. The summaries are readable, reasonably well-formed and are informative enough to convey the major opinions.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Omelianchuk, Kostiantyn</author><author>Atrasevych, Vitaliy</author><author>Chernodub, Artem</author><author>Skurzhanskyi, Oleksandr</author></authors></contributors><titles><title>GECToR - Grammatical error correction: Tag, not rewrite</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><issue>April</issue><keywords/><dates><year>2020</year></dates><electronic-resource-num>10.18653/v1/2020.bea-1.16</electronic-resource-num><urls/><label>Read</label><abstract>In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model/ensemble GEC tagger achieves an F0.5 of 65.3/66.5 on CoNLL-2014 (test) and F0.5 of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system. The code and trained models are publicly available1.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Xiao, Dongling</author><author>Zhang, Han</author><author>Li, Yukun</author><author>Sun, Yu</author><author>Tian, Hao</author><author>Wu, Hua</author><author>Wang, Haifeng</author></authors></contributors><titles><title>ERNIE-GEN: An enhanced multi-flow pre-training and fine-tuning framework for natural language generation</title><secondary-title>IJCAI International Joint Conference on Artificial Intelligence</secondary-title></titles><periodical><full-title>IJCAI International Joint Conference on Artificial Intelligence</full-title></periodical><pages>3997-4003</pages><volume>2021-Janua</volume><keywords/><dates><year>2020</year></dates><isbn>9780999241165</isbn><electronic-resource-num>10.24963/ijcai.2020/553</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Xiao et al. - 2020 - ERNIE-GEN An enhanced multi-flow pre-training and fine-tuning framework for natural language generation.pdf</url></pdf-urls></urls><label>Printed</label><abstract>Current pre-training works in natural language generation pay little attention to the problem of exposure bias on downstream tasks. To address this issue, we propose an enhanced multi-flow sequence to sequence pre-training and fine-tuning framework named ERNIE-GEN, which bridges the discrepancy between training and inference with an infilling generation mechanism and a noise-aware generation method. To make generation closer to human writing patterns, this framework introduces a span-by-span generation flow that trains the model to predict semantically-complete spans consecutively rather than predicting word by word. Unlike existing pre-training methods, ERNIE-GEN incorporates multi-granularity target sampling to construct pre-training data, which enhances the correlation between encoder and decoder. Experimental results demonstrate that ERNIE-GEN achieves state-of-the-art results with a much smaller amount of pre-training data and parameters on a range of language generation tasks, including abstractive summarization (Gigaword and CNN/DailyMail), question generation (SQuAD), dialogue response generation (Persona-Chat) and generative question answering (CoQA). The source codes and pretrained models have been released at https://github.com/PaddlePaddle/ERNIE.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Inkeles, Megan S.</author><author>Scumpia, Philip O.</author><author>Swindell, William R.</author><author>Lopez, David</author><author>Teles, Rosane M.B.</author><author>Graeber, Thomas G.</author><author>Meller, Stephan</author><author>Homey, Bernhard</author><author>Elder, James T.</author><author>Gilliet, Michel</author><author>Modlin, Robert L.</author><author>Pellegrini, Matteo</author></authors></contributors><titles><title>Comparison of molecular signatures from multiple skin diseases identifies mechanisms of immunopathogenesis</title><secondary-title>Journal of Investigative Dermatology</secondary-title></titles><periodical><full-title>Journal of Investigative Dermatology</full-title></periodical><pages>151-159</pages><volume>135</volume><issue>1</issue><keywords/><dates><year>2015</year></dates><publisher>Elsevier Masson SAS</publisher><accession-num>25111617</accession-num><electronic-resource-num>10.1038/jid.2014.352</electronic-resource-num><notes>Data owner mentioned you cannot compare different skin diseases through the same data because of the use of different microarrays to measure.
Is there a way to correct for different microarrays?</notes><research-notes>Data owner mentioned you cannot compare different skin diseases through the same data because of the use of different microarrays to measure.
Is there a way to correct for different microarrays?</research-notes><urls><pdf-urls><url>internal-pdf://Inkeles et al. - 2015 - Comparison of molecular signatures from multiple skin diseases identifies mechanisms of immunopathogenesis.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1038/jid.2014.352</url></web-urls></urls><abstract>The ability to obtain gene expression profiles from human disease specimens provides an opportunity to identify relevant gene pathways, but is limited by the absence of data sets spanning a broad range of conditions. Here, we analyzed publicly available microarray data from 16 diverse skin conditions in order to gain insight into disease pathogenesis. Unsupervised hierarchical clustering separated samples by disease as well as common cellular and molecular pathways. Disease-specific signatures were leveraged to build a multi-disease classifier, which predicted the diagnosis of publicly and prospectively collected expression profiles with 93% accuracy. In one sample, the molecular classifier differed from the initial clinical diagnosis and correctly predicted the eventual diagnosis as the clinical presentation evolved. Finally, integration of IFN-regulated gene programs with the skin database revealed a significant inverse correlation between IFN-β and IFN-γ programs across all conditions. Our study provides an integrative approach to the study of gene signatures from multiple skin conditions, elucidating mechanisms of disease pathogenesis. In addition, these studies provide a framework for developing tools for personalized medicine toward the precise prediction, prevention, and treatment of disease on an individual level.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Yizhe</author><author>Sun, Siqi</author><author>Galley, Michel</author><author>Chen, Yen Chun</author><author>Brockett, Chris</author><author>Gao, Xiang</author><author>Gao, Jianfeng</author><author>Liu, Jingjing</author><author>Dolan, Bill</author></authors></contributors><titles><title>Dialogpt : Large-scale generative pre-training for conversational response generation</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.18653/v1/2020.acl-demos.30</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Zhang et al. - 2019 - Dialogpt Large-scale generative pre-training for conversational response generation.pdf</url></pdf-urls></urls><abstract>We present a large, tunable neural conversational response generation model, DIALOGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent opendomain dialogue systems.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Abdollahi, Behnoush</author><author>Nasraoui, Olfa</author></authors></contributors><titles><title>Using explainability for constrained matrix factorization</title><secondary-title>RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems</secondary-title></titles><periodical><full-title>RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems</full-title></periodical><pages>79-83</pages><keywords/><dates><year>2017</year></dates><isbn>9781450346528</isbn><electronic-resource-num>10.1145/3109859.3109913</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Abdollahi, Nasraoui - 2017 - Using explainability for constrained matrix factorization.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Accurate model-based Collaborative Filtering (CF) approaches, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. Yet explanations have been shown to improve the transparency of a recommender system by justifying recommendations, and this in turn can enhance the user's trust in the recommendations. Hence, one main challenge in designing a recommender system is mitigating the trade-off between an explainable technique with moderate prediction accuracy and a more accurate technique with no explainable recommendations. In this paper, we focus on factorization models and further assume the absence of any additional data source, such as item content or user attributes. We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is effective in generating accurate and explainable recommendations.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Defferrard, Michaël</author><author>Bresson, Xavier</author><author>Vandergheynst, Pierre</author></authors></contributors><titles><title>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title><secondary-title>Proceedings of the 30th International Conference on Neural Information Processing Systems</secondary-title></titles><periodical><full-title>Proceedings of the 30th International Conference on Neural Information Processing Systems</full-title></periodical><pages>3844-3852</pages><keywords/><dates><year>2016</year></dates><pub-location>USA</pub-location><publisher>Curran Associates Inc.</publisher><isbn>978-1-5108-3881-9</isbn><urls><pdf-urls><url>internal-pdf://Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=3157382.3157527</url></web-urls></urls><label>Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Severinski, Cody</author><author>Salakhutdinov, Ruslan</author></authors></contributors><titles><title>Bayesian Probabilistic Matrix Factorization: A User Frequency Analysis</title></titles><periodical/><keywords/><dates><year>2014</year></dates><urls><pdf-urls><url>internal-pdf://Bayesian Probabilistic Matrix Factorization A User Frequency Analysis.pdf</url></pdf-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Hu, Yifan</author><author>Koren, Yehuda</author><author>Volinsky, Chris</author></authors></contributors><titles><title>Collaborative Filtering for Implicit Feedback Datasets</title><secondary-title>Proceedings of the 2008 Eighth IEEE International Conference on Data Mining</secondary-title></titles><periodical><full-title>Proceedings of the 2008 Eighth IEEE International Conference on Data Mining</full-title></periodical><pages>263-272</pages><keywords><keyword>Collaborative filtering</keyword><keyword>implicit feedback</keyword><keyword>recommender system</keyword></keywords><dates><year>2008</year></dates><pub-location>Washington, DC, USA</pub-location><publisher>IEEE Computer Society</publisher><isbn>978-0-7695-3502-9</isbn><electronic-resource-num>10.1109/ICDM.2008.22</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Collaborative Filtering for Implicit Feedback Datasets.pdf</url></pdf-urls><web-urls><url>https://doi.org/10.1109/ICDM.2008.22</url></web-urls></urls><label>Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Weston, Jason</author><author>Dinan, Emily</author><author>Miller, Alexander H.</author></authors></contributors><titles><title>Retrieve and refine: Improved sequence generation models for dialogue</title><secondary-title>arXiv</secondary-title></titles><periodical><full-title>arXiv</full-title></periodical><pages>87-92</pages><keywords/><dates><year>2018</year></dates><isbn>9781948087759</isbn><electronic-resource-num>10.18653/v1/w18-5713</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Weston, Dinan, Miller - 2018 - Retrieve and refine Improved sequence generation models for dialogue.pdf</url></pdf-urls></urls><abstract>Sequence generation models for dialogue are known to have several problems: they tend to produce short, generic sentences that are uninformative and unengaging. Retrieval models on the other hand can surface interesting responses, but are restricted to the given retrieval set leading to erroneous replies that cannot be tuned to the specific context. In this work we develop a model that combines the two approaches to avoid both their deficiencies: first retrieve a response and then refine it - the final sequence generator treating the retrieval as additional context. We show on the recent CONVAI2 challenge task our approach produces responses superior to both standard retrieval and generation models in human evaluations.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Salakhutdinov, Ruslan</author><author>Mnih, Andriy</author></authors></contributors><titles><title>Probabilistic Matrix Factorization</title><secondary-title>Proceedings of the 20th International Conference on Neural Information Processing Systems</secondary-title></titles><periodical><full-title>Proceedings of the 20th International Conference on Neural Information Processing Systems</full-title></periodical><pages>1257-1264</pages><keywords/><dates><year>2007</year></dates><pub-location>USA</pub-location><publisher>Curran Associates Inc.</publisher><isbn>978-1-60560-352-0</isbn><urls><pdf-urls><url>internal-pdf://Probabilistic Matrix Factorization.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=2981562.2981720</url></web-urls></urls><label>Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Vaswani, Ashish</author><author>Shazeer, Noam</author><author>Parmar, Niki</author><author>Uszkoreit, Jakob</author><author>Jones, Llion</author><author>Gomez, Aidan N.</author><author>Kaiser, Łukasz</author><author>Polosukhin, Illia</author></authors></contributors><titles><title>Attention is all you need</title><secondary-title>Advances in Neural Information Processing Systems</secondary-title></titles><periodical><full-title>Advances in Neural Information Processing Systems</full-title></periodical><pages>5999-6009</pages><volume>2017-Decem</volume><keywords/><dates><year>2017</year></dates><pub-location>USA</pub-location><publisher>Curran Associates Inc.</publisher><isbn>978-1-5108-6096-4</isbn><urls><pdf-urls><url>internal-pdf://Attention Is All You Need.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=3295222.3295349</url></web-urls></urls><label>Printed;Read</label><abstract>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yang, Runqi</author><author>Zhang, Jianhai</author><author>Gao, Xing</author><author>Ji, Feng</author><author>Chen, Haiqing</author></authors></contributors><titles><title>Simple and effective text matching with richer alignment features</title><secondary-title>ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference</secondary-title></titles><periodical><full-title>ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference</full-title></periodical><pages>4699-4709</pages><keywords/><dates><year>2020</year></dates><isbn>9781950737482</isbn><electronic-resource-num>10.18653/v1/p19-1465</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Yang et al. - 2020 - Simple and effective text matching with richer alignment features.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>In this paper, we present a fast and strong neural approach for general purpose text matching applications. We explore what is sufficient to build a fast and well-performed text matching model and propose to keep three key features available for inter-sequence alignment: original point-wise features, previous aligned features, and contextual features while simplifying all the remaining components. We conduct experiments on four well-studied benchmark datasets across tasks of natural language inference, paraphrase identification and answer selection. The performance of our model is on par with the state-of-the-art on all datasets with much fewer parameters and the inference speed is at least 6 times faster compared with similarly performed ones.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nowlan, Steven J</author><author>Hinton, Geoffrey E</author></authors></contributors><titles><title>Simplifying Neural Networks by Soft Weight-sharing</title><secondary-title>Neural Comput.</secondary-title></titles><periodical><full-title>Neural Comput.</full-title></periodical><pages>473-493</pages><volume>4</volume><issue>4</issue><keywords/><dates><year>1992</year></dates><pub-location>Cambridge, MA, USA</pub-location><publisher>MIT Press</publisher><electronic-resource-num>10.1162/neco.1992.4.4.473</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Simplifying Neural Networks by Soft Weight-Sharing.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1162/neco.1992.4.4.473</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rusu, Andrei A.</author><author>Colmenarejo, Sergio Gómez</author><author>Gülçehre, Çaglar</author><author>Desjardins, Guillaume</author><author>Kirkpatrick, James</author><author>Pascanu, Razvan</author><author>Mnih, Volodymyr</author><author>Kavukcuoglu, Koray</author><author>Hadsell, Raia</author></authors></contributors><titles><title>Policy distillation</title><secondary-title>4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings</secondary-title></titles><periodical><full-title>4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings</full-title></periodical><pages>1-13</pages><keywords/><dates><year>2016</year></dates><urls><pdf-urls><url>internal-pdf://Rusu et al. - 2016 - Policy distillation.pdf</url></pdf-urls></urls><abstract>Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>McCall, Matthew N.</author><author>Bolstad, Benjamin M.</author><author>Irizarry, Rafael A.</author></authors></contributors><titles><title>Frozen robust multiarray analysis (fRMA)</title><secondary-title>Biostatistics</secondary-title></titles><periodical><full-title>Biostatistics</full-title></periodical><pages>242-253</pages><volume>11</volume><issue>2</issue><keywords><keyword>Affymetrix</keyword><keyword>ArrayExpress</keyword><keyword>GEO</keyword><keyword>Microarray</keyword><keyword>Preprocessing</keyword><keyword>Single-array</keyword></keywords><dates><year>2010</year></dates><accession-num>20097884</accession-num><electronic-resource-num>10.1093/biostatistics/kxp059</electronic-resource-num><urls><pdf-urls><url>internal-pdf://McCall, Bolstad, Irizarry - 2010 - Frozen robust multiarray analysis (fRMA).pdf</url></pdf-urls></urls><abstract>Robust multiarray analysis (RMA) is the most widely used preprocessing algorithm for Affymetrix and Nimblegen gene expression microarrays. RMA performs background correction, normalization, and summarization in a modular way. The last 2 steps require multiple arrays to be analyzed simultaneously. The ability to borrow information across samples provides RMA various advantages. For example, the summarization step fits a parametric model that accounts for probe effects, assumed to be fixed across arrays, and improves outlier detection. Residuals, obtained from the fitted model, permit the creation of useful quality metrics. However, the dependence on multiple arrays has 2 drawbacks: (1) RMA cannot be used in clinical settings where samples must be processed individually or in small batches and (2) data sets preprocessed separately are not comparable. We propose a preprocessing algorithm, frozen RMA (fRMA), which allows one to analyze microarrays individually or in small batches and then combine the data for analysis. This is accomplished by utilizing information from the large publicly available microarray databases. In particular, estimates of probe-specific effects and variances are precomputed and frozen. Then, with new data sets, these are used in concert with information from the new arrays to normalize and summarize the data. We find that fRMA is comparable to RMA when the data are analyzed as a single batch and outperforms RMA when analyzing multiple batches. The methods described here are implemented in the R package fRMA and are currently available for download from the software section of http://rafalab.jhsph.edu.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kanagawa, Heishiro</author><author>Kobayashi, Hayato</author><author>Shimizu, Nobuyuki</author><author>Tagami, Yukihiro</author><author>Suzuki, Taiji</author></authors></contributors><titles><title>Cross-domain recommendation via deep domain adaptation</title><secondary-title>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</secondary-title></titles><periodical><full-title>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</full-title></periodical><pages>20-29</pages><volume>11438 LNCS</volume><keywords><keyword>Cross-domain recommendation</keyword><keyword>Deep domain adaptation</keyword></keywords><dates><year>2019</year></dates><isbn>9783030157180</isbn><electronic-resource-num>10.1007/978-3-030-15719-7_3</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Kanagawa et al. - 2019 - Cross-domain recommendation via deep domain adaptation.pdf</url></pdf-urls></urls><abstract>The behavior of users in certain services indicates their preferences, which may be used to make recommendations for other services they have never used. However, the cross-domain relation between items and user preferences is not simple, especially when there are few or no common users and items across domains. We propose a content-based cross-domain recommendation method for cold-start users that does not require user- or item-overlap. We formulate recommendations as an extreme classification task, and the problem is treated as an instance of unsupervised domain adaptation. We assess the performance of the approach in experiments on large datasets collected from Yahoo! JAPAN video and news services and find that it outperforms several baseline methods including a cross-domain collaborative filtering method.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mnih, Volodymyr</author><author>Kavukcuoglu, Koray</author><author>Silver, David</author><author>Rusu, Andrei A.</author><author>Veness, Joel</author><author>Bellemare, Marc G.</author><author>Graves, Alex</author><author>Riedmiller, Martin</author><author>Fidjeland, Andreas K.</author><author>Ostrovski, Georg</author><author>Petersen, Stig</author><author>Beattie, Charles</author><author>Sadik, Amir</author><author>Antonoglou, Ioannis</author><author>King, Helen</author><author>Kumaran, Dharshan</author><author>Wierstra, Daan</author><author>Legg, Shane</author><author>Hassabis, Demis</author></authors></contributors><titles><title>Human-level control through deep reinforcement learning</title><secondary-title>Nature</secondary-title></titles><periodical><full-title>Nature</full-title></periodical><pages>529-533</pages><volume>518</volume><issue>7540</issue><keywords/><dates><year>2015</year></dates><publisher>Nature Publishing Group</publisher><accession-num>25719670</accession-num><electronic-resource-num>10.1038/nature14236</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Human-level control through deep reinforcement learning.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1038/nature14236</url></web-urls></urls><abstract>The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rastegarpanah, Bashir</author><author>Crovella, Mark</author><author>Gummadi, Krishna P</author></authors></contributors><titles><title>Exploring Explanations for Matrix Factorization Recommender Systems</title><secondary-title>Fatrec 2017</secondary-title></titles><periodical><full-title>Fatrec 2017</full-title></periodical><issue>1</issue><keywords/><dates><year>2017</year></dates><electronic-resource-num>10.18122/B2R717</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Rastegarpanah, Crovella, Gummadi - 2017 - Exploring Explanations for Matrix Factorization Recommender Systems.pdf</url></pdf-urls><web-urls><url>https://doi.org/10.18122/B2R717</url></web-urls></urls><label>Printed;Read</label><abstract>In this paper we address the problem of finding explanations for collaborative filtering algorithms that use matrix factorization methods. We look for explanations that increase the transparency of the system. To do so, we propose two measures. First, we show a model that describes the contribution of each previous rating given by a user to the generated recommendation. Second, we measure the influence of changing each previous rating of a user on the outcome of the recommender system. We show that under the assumption that there are many more users in the system than there are items, we can efficiently generate each type of explanation by using linear approximations of the recommender system's behavior for each user, and computing partial derivatives of predicted ratings with respect to each user's provided ratings.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Yoshioka, Takuya</author><author>Nakatani, Tomohiro</author></authors></contributors><titles><title>Generalization of multi-channel linear prediction methods for blind MIMO impulse response shortening</title><secondary-title>IEEE Transactions on Audio, Speech and Language Processing</secondary-title></titles><periodical><full-title>IEEE Transactions on Audio, Speech and Language Processing</full-title></periodical><pages>2707-2720</pages><volume>20</volume><issue>10</issue><keywords><keyword>Blind equalization</keyword><keyword>dereverberation</keyword><keyword>linear prediction MIMO</keyword></keywords><dates><year>2012</year></dates><electronic-resource-num>10.1109/TASL.2012.2210879</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Yoshioka, Nakatani - 2012 - Generalization of multi-channel linear prediction methods for blind MIMO impulse response shortening.pdf</url></pdf-urls></urls><abstract>The performance of many microphone array processing techniques deteriorates in the presence of reverberation. To provide a widely applicable solution to this longstanding problem, this paper generalizes existing dereverberation methods using subband-domain multi-channel linear prediction filters so that the resultant generalized algorithm can blindly shorten a multiple-input multiple-output (MIMO) room impulse response between a set of unknown number of sources and a microphone array. Unlike existing dereverberation methods, the presented algorithm is developed without assuming specific acoustic conditions, and provides a firm theoretical underpinning for the applicability of the subband-domain multi-channel linear prediction methods. The generalization is achieved by using a new cost function for estimating the prediction filter and an efficient optimization algorithm. The proposed generalized algorithm makes it easier to understand the common background underlying different dereverberation methods and future technical development. Indeed, this paper also derives two alternative dereverberation methods from the proposed algorithm, which are advantageous in terms of computational complexity. Experimental results are reported, showing that the proposed generalized algorithm effectively achieves blind MIMO impulse response shortening especially in a mid-to-high frequency range. © 2012 IEEE.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Campbell, Joshua Charles</author><author>Hindle, Abram</author><author>Stroulia, Eleni</author></authors></contributors><titles><title>Latent Dirichlet Allocation: Extracting Topics from Software Engineering Data</title><secondary-title>The Art and Science of Analyzing Software Data</secondary-title></titles><periodical><full-title>The Art and Science of Analyzing Software Data</full-title></periodical><pages>139-159</pages><volume>3</volume><keywords><keyword>Latent Dirichlet allocation</keyword><keyword>Software engineering</keyword><keyword>Topic modeling</keyword><keyword>Tutorial</keyword></keywords><dates><year>2003</year></dates><isbn>9780124115439</isbn><electronic-resource-num>10.1016/B978-0-12-411519-4.00006-9</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Campbell, Hindle, Stroulia - 2003 - Latent Dirichlet Allocation Extracting Topics from Software Engineering Data.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Topic analysis is a powerful tool that extracts &quot;topics&quot; from document collections. Unlike manual tagging, which is effort intensive and requires expertise in the documents' subject matter, topic analysis (in its simplest form) is an automated process. Relying on the assumption that each document in a collection refers to a small number of topics, it extracts bags of words attributable to these topics. These topics can be used to support document retrieval or to relate documents to each other through their associated topics. Given the variety and amount of textual information included in software repositories, in issue reports, in commit and source-code comments, and in other forms of documentation, this method has found many applications in the software-engineering field of mining software repositories.This chapter provides an overview of the theory underlying latent Dirichlet allocation (LDA), the most popular topic-analysis method today. Next, it illustrates, with a brief tutorial introduction, how to employ LDA on a textual data set. Third, it reviews the software-engineering literature for uses of LDA for analyzing textual software-development assets, in order to support developers' activities. Finally, we discuss the interpretability of the automatically extracted topics, and their correlation with tags provided by subject-matter experts.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Foster, Blake</author><author>Mahadevan, Sridhar</author><author>Wang, Rui</author></authors></contributors><titles><title>A GPU-based Approximate SVD Algorithm</title><secondary-title>Proceedings of the 9th International Conference on Parallel Processing and Applied Mathematics - Volume Part I</secondary-title></titles><periodical><full-title>Proceedings of the 9th International Conference on Parallel Processing and Applied Mathematics - Volume Part I</full-title></periodical><pages>569-578</pages><keywords><keyword>GPU</keyword><keyword>SVD</keyword><keyword>cosine trees</keyword><keyword>out-of-core computation</keyword></keywords><dates><year>2012</year></dates><pub-location>Berlin, Heidelberg</pub-location><publisher>Springer-Verlag</publisher><isbn>978-3-642-31463-6</isbn><electronic-resource-num>10.1007/978-3-642-31464-3_58</electronic-resource-num><urls><pdf-urls><url>internal-pdf://A GPU-based Approximate SVD Algorithm.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1007/978-3-642-31464-3_58</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Dang, Hoang Vu</author></authors></contributors><titles><title>Feature normalization for similarity calculations in matrix factorization method</title><secondary-title>Proceedings of 2018 10th International Conference on Knowledge and Systems Engineering, KSE 2018</secondary-title></titles><periodical><full-title>Proceedings of 2018 10th International Conference on Knowledge and Systems Engineering, KSE 2018</full-title></periodical><pages>230-235</pages><keywords/><dates><year>2018</year></dates><publisher>IEEE</publisher><isbn>9781538661130</isbn><electronic-resource-num>10.1109/KSE.2018.8573347</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Dang - 2018 - Feature normalization for similarity calculations in matrix factorization method.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Matrix factorization is a well-established approach in recommender systems with its roots in document retrieval. In this approach the original matrix of interactions between users and items is approximately factorized into matrices representing user features and item features. In this paper we argue for an orthogonality condition, under which the rows of the user feature matrix can be used to estimate similarity between users (and similarly for item similarity). Furthermore we provide an algebraic derivation of a normalization procedure to ensure that orthogonality conditions holds for any matrix factorization technique regardless of the rank of the factors. Finally we demonstrate the improvement in similarity ratings when the aforementioned normalization is applied to both explicit ratings and implicit feedback datasets, using the Alternating Least Square with Weighted λ-Regularization and Bayesian Probabilistic Matrix Factorization models.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhao, Lili</author><author>Pan, Sinno Jialin</author><author>Xiang, Evan Wei</author><author>Zhong, Erheng</author><author>Lu, Zhongqi</author><author>Yang, Qiang</author></authors></contributors><titles><title>Active transfer learning for cross-system recommendation</title><secondary-title>Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013</secondary-title></titles><periodical><full-title>Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013</full-title></periodical><pages>1205-1211</pages><keywords><keyword>Special Track on Artificial Intelligence and the W</keyword></keywords><dates><year>2013</year></dates><isbn>9781577356158</isbn><urls><pdf-urls><url>internal-pdf://Zhao et al. - 2013 - Active transfer learning for cross-system recommendation.pdf</url></pdf-urls></urls><abstract>Recommender systems, especially the newly launched ones, have to deal with the data-sparsity issue, where little existing rating information is available. Recently, transfer learning has been proposed to address this problem by leveraging the knowledge from related recommender systems where rich collaborative data are available. However, most previous transfer learning models assume that entity-correspondences across different systems are given as input, which means that for any entity (e.g., a user or an item) in a target system, its corresponding entity in a source system is known. This assumption can hardly be satisfied in real-world scenarios where entity-correspondences across systems are usually unknown, and the cost of identifying them can be expensive. For example, it is extremely difficult to identify whether a user A from Facebook and a user B from Twitter are the same person. In this paper, we propose a framework to construct entity correspondence with limited budget by using active learning to facilitate knowledge transfer across recommender systems. Specifically, for the purpose of maximizing knowledge transfer, we first iteratively select entities in the target system based on our proposed criterion to query their correspondences in the source system. We then plug the actively constructed entity-correspondence mapping into a general transferred collaborative-filtering model to improve recommendation quality.We perform extensive experiments on real world datasets to verify the effectiveness of our proposed framework for this crosssystem recommendation problem. Copyright © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Holmes, Michael</author><author>Gray, Alexander</author><author>Jr, Charles</author></authors></contributors><titles><title>QUIC-SVD: Fast SVD using cosine trees</title></titles><periodical/><pages>673-680</pages><volume>21</volume><keywords/><dates><year>2008</year></dates><urls><pdf-urls><url>internal-pdf://QUIC-SVD Fast SVD Using Cosine Trees.pdf</url></pdf-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Smith, Leslie N.</author></authors></contributors><titles><title>Cyclical learning rates for training neural networks</title><secondary-title>Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017</secondary-title></titles><periodical><full-title>Proceedings - 2017 IEEE Winter Conference on Applications of Computer Vision, WACV 2017</full-title></periodical><pages>464-472</pages><issue>April</issue><keywords/><dates><year>2017</year></dates><isbn>9781509048229</isbn><electronic-resource-num>10.1109/WACV.2017.58</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Smith - 2017 - Cyclical learning rates for training neural networks.pdf</url></pdf-urls></urls><label>Read</label><abstract>It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate 'reasonable bounds' - linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Liu, Yang</author><author>Lapata, Mirella</author></authors></contributors><titles><title>Text summarization with pretrained encoders</title><secondary-title>EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference</secondary-title></titles><periodical><full-title>EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference</full-title></periodical><pages>3730-3740</pages><keywords/><dates><year>2020</year></dates><isbn>9781950737901</isbn><electronic-resource-num>10.18653/v1/d19-1387</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Liu, Lapata - 2020 - Text summarization with pretrained encoders.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Bidirectional Encoder Representations from Transformers (BERT; Devlin et al. 2019) represents the latest incarnation of pretrained language models which have recently advanced a wide range of natural language processing tasks. In this paper, we showcase how BERT can be usefully applied in text summarization and propose a general framework for both extractive and abstractive models. We introduce a novel document-level encoder based on BERT which is able to express the semantics of a document and obtain representations for its sentences. Our extractive model is built on top of this encoder by stacking several inter-sentence Transformer layers. For abstractive summarization, we propose a new fine-tuning schedule which adopts different optimizers for the encoder and the decoder as a means of alleviating the mismatch between the two (the former is pretrained while the latter is not). We also demonstrate that a two-staged fine-tuning approach can further boost the quality of the generated summaries. Experiments on three datasets show that our model achieves state-of-the-art results across the board in both extractive and abstractive settings.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Lynch, Tiina</author><author>Ghergulescu, Ioana</author></authors></contributors><titles><title>Large Scale Evaluation of Learning Flow</title><secondary-title>Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017</secondary-title></titles><periodical><full-title>Proceedings - IEEE 17th International Conference on Advanced Learning Technologies, ICALT 2017</full-title></periodical><pages>62-64</pages><keywords><keyword>adaptive learning</keyword><keyword>flow</keyword><keyword>learning analytics</keyword><keyword>personalization</keyword><keyword>user feedback</keyword></keywords><dates><year>2017</year></dates><isbn>9781538638705</isbn><electronic-resource-num>10.1109/ICALT.2017.98</electronic-resource-num><notes>Adaptemy research suggested by Tim Hesse.</notes><research-notes>Adaptemy research suggested by Tim Hesse.</research-notes><urls><pdf-urls><url>internal-pdf://Lynch, Ghergulescu - 2017 - Large Scale Evaluation of Learning Flow.pdf</url></pdf-urls></urls><abstract>Personalized and adaptive learning is the fastest growing field in e-learning. Adaptive e-learning systems are typically well suited for real-world heterogeneous users, which exhibit different levels of motivation and knowledge. Furthermore, students learn best when they are in flow, i.e. when the level of difficulty is perfectly adjusted to their individual abilities. A personalized, adaptive, and intelligent learning environment can provide each student with this learning experience. In this paper, we present a large-scale evaluation of learning in flow within an adaptive and personalized system, the Adaptemy system. The paper presents the results of two studies: an objective study with 7,614 Irish secondary school students in math classes assessing their learning flow, and a subjective study with 80 students assessing their perceived learning experience. The results from the objective study show that 88% of the students worked within the flow channel. In the subjective study, 70% of students reported a perceived improvement in their math skills after the exercise studying with the adaptive and intelligent learning system.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Li, Pan</author><author>Tuzhilin, Alexander</author></authors></contributors><titles><title>DDTCDR: Deep dual transfer cross domain recommendation</title><secondary-title>WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining</secondary-title></titles><periodical><full-title>WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining</full-title></periodical><pages>331-339</pages><keywords><keyword>Autoencoder</keyword><keyword>Cross domain recommendation</keyword><keyword>Deep learning</keyword><keyword>Dual learning</keyword><keyword>Transfer learning</keyword></keywords><dates><year>2020</year></dates><isbn>9781450368223</isbn><electronic-resource-num>10.1145/3336191.3371793</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Li, Tuzhilin - 2020 - DDTCDR Deep dual transfer cross domain recommendation.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Cross domain recommender systems have been increasingly valuable for helping consumers identify the most satisfying items from different categories. However, previously proposed cross-domain models did not take into account bidirectional latent relations between users and items. In addition, they do not explicitly model information of user and item features, while utilizing only user ratings information for recommendations. To address these concerns, in this paper we propose a novel approach to cross-domain recommendations based on the mechanism of dual learning that transfers information between two related domains in an iterative manner until the learning process stabilizes. We develop a novel latent orthogonal mapping to extract user preferences over multiple domains while preserving relations between users across different latent spaces. Combining with autoencoder approach to extract the latent essence of feature information, we propose Deep Dual Transfer Cross Domain Recommendation (DDTCDR) model to provide recommendations in respective domains. We test the proposed method on a large dataset containing three domains of movies, book and music items and demonstrate that it consistently and significantly outperforms several state-of-the-art baselines and also classical transfer learning approaches.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Koren, Yehuda</author><author>Bell, Robert</author><author>Volinsky, Chris</author></authors></contributors><titles><title>Matrix Factorization Techniques for Recommender Systems</title><secondary-title>Computer</secondary-title></titles><periodical><full-title>Computer</full-title></periodical><pages>30-37</pages><volume>42</volume><issue>8</issue><keywords><keyword>Computational intelligence</keyword><keyword>Matrix factorization</keyword><keyword>Netflix Prize</keyword></keywords><dates><year>2009</year></dates><pub-location>Los Alamitos, CA, USA</pub-location><publisher>IEEE Computer Society Press</publisher><electronic-resource-num>10.1109/MC.2009.263</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Matrix Factorization Techniques for Recommender Systems.pdf</url></pdf-urls><web-urls><url>https://doi.org/10.1109/MC.2009.263</url></web-urls></urls><label>Printed;Read</label><abstract>Matrix factorization</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Berg, Rianne van den</author><author>Kipf, Thomas N.</author><author>Welling, Max</author></authors></contributors><titles><title>Graph Convolutional Matrix Completion</title></titles><periodical/><keywords/><dates><year>2017</year></dates><urls><pdf-urls><url>internal-pdf://Berg, Kipf, Welling - 2017 - Graph Convolutional Matrix Completion.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1706.02263</url></web-urls></urls><label>Printed;Read</label><abstract>We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jang, Yunhun</author><author>Lee, Hankook</author><author>Hwang, Sung Ju</author><author>Shin, Jinwoo</author></authors></contributors><titles><title>Learning what and where to transfer</title><secondary-title>36th International Conference on Machine Learning, ICML 2019</secondary-title></titles><periodical><full-title>36th International Conference on Machine Learning, ICML 2019</full-title></periodical><pages>5360-5369</pages><volume>2019-June</volume><keywords/><dates><year>2019</year></dates><isbn>9781510886988</isbn><urls><pdf-urls><url>internal-pdf://Jang et al. - 2019 - Learning what and where to transfer.pdf</url></pdf-urls></urls><abstract>As the application of deep learning has expanded to real-world problems' with insufficient volume of training data, transfer learning recently has gained much attention as means of improving the performance in such small-data regime. However, when existing methods are applied between heterogeneous architectures and tasks, it becomes more important to manage their detailed configurations and often requires exhaustive tuning on them for the desired performance. To address the issue, we propose a novel transfer learning approach based on meta-learning that can automatically learn what knowledge to transfer from the source network to where in the target network. Given source and target networks, we propose an efficient training scheme to learn mcta-networks that decide (a) which pairs of layers between the source and target networks should be matched for knowledge transfer and (b) which features and how much knowledge from each feature should be transferred. We validate our meta-transfer approach against recent transfer learning methods on various datasets and network architectures, on which our automated scheme significantly outperforms the prior baselines that find &quot;what and where to transfer&quot; in a hand-crafted manner.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Wang, Jizhe</author><author>Huang, Pipei</author><author>Zhao, Huan</author><author>Zhang, Zhibo</author><author>Zhao, Binqiang</author><author>Lee, Dik Lun</author></authors></contributors><titles><title>Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba</title><secondary-title>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;#38; Data Mining</secondary-title></titles><periodical><full-title>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp;#38; Data Mining</full-title></periodical><pages>839-848</pages><keywords><keyword>collaborative filtering</keyword><keyword>e-commerce recommendation</keyword><keyword>graph embedding</keyword><keyword>recommendation system</keyword></keywords><dates><year>2018</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-5552-0</isbn><electronic-resource-num>10.1145/3219819.3219869</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Billion-scale Commodity Embedding for Ecommerce in Alibaba‌.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/3219819.3219869</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Kiros, Ryan</author><author>Zhu, Yukun</author><author>Salakhutdinov, Ruslan</author><author>Zemel, Richard S.</author><author>Torralba, Antonio</author><author>Urtasun, Raquel</author><author>Fidler, Sanja</author></authors></contributors><titles><title>Skip-thought vectors</title><secondary-title>Advances in Neural Information Processing Systems</secondary-title></titles><periodical><full-title>Advances in Neural Information Processing Systems</full-title></periodical><pages>3294-3302</pages><volume>2015-Janua</volume><issue>786</issue><keywords/><dates><year>2015</year></dates><notes>Highly cited Skip-thought vectors.
Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</notes><research-notes>Highly cited Skip-thought vectors.
Referenced in Unsupervised Text Summarization Using Sentence Emeddings.</research-notes><urls><pdf-urls><url>internal-pdf://Kiros et al. - 2015 - Skip-thought vectors.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Takács, Gábor</author><author>Pilászy, István</author><author>Tikk, Domonkos</author></authors></contributors><titles><title>Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering</title><secondary-title>Proceedings of the Fifth ACM Conference on Recommender Systems</secondary-title></titles><periodical><full-title>Proceedings of the Fifth ACM Conference on Recommender Systems</full-title></periodical><pages>297-300</pages><keywords><keyword>collaborative filtering</keyword><keyword>conjugate gradient method</keyword></keywords><dates><year>2011</year></dates><pub-location>New York, NY, USA</pub-location><publisher>ACM</publisher><isbn>978-1-4503-0683-6</isbn><electronic-resource-num>10.1145/2043932.2043987</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Applications of the Conjugate Gradient Method for Implicit Feedback Collaborative Filtering.pdf</url></pdf-urls><web-urls><url>http://doi.acm.org/10.1145/2043932.2043987</url></web-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Schafer, J. Ben</author><author>Frankowski, Dan</author><author>Herlocker, Jon</author><author>Sen, Shilad</author></authors></contributors><titles><title>Collaborative filtering recommender systems</title><secondary-title>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</secondary-title></titles><periodical><full-title>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</full-title></periodical><pages>291-324</pages><volume>4321 LNCS</volume><issue>1</issue><keywords/><dates><year>2007</year></dates><isbn>3540720782</isbn><electronic-resource-num>10.1007/978-3-540-72079-9_9</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Schafer et al. - 2007 - Collaborative filtering recommender systems.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>One of the potent personalization technologies powering the adaptive web is collaborative filtering. Collaborative filtering (CF) is the process of filtering or evaluating items through the opinions of other people. CF technology brings together the opinions of large interconnected communities on the web, supporting filtering of substantial quantities of data. In this chapter we introduce the core concepts of collaborative filtering, its primary uses for users of the adaptive web, the theory and practice of CF algorithms, and design decisions regarding rating systems and acquisition of ratings. We also discuss how to evaluate CF systems, and the evolution of rich interaction interfaces. We close the chapter with discussions of the challenges of privacy particular to a CF recommendation service and important open research questions in the field. © Springer-Verlag Berlin Heidelberg 2007.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cunha, Tiago</author><author>Soares, Carlos</author><author>de Carvalho, André C.P.L.F.</author></authors></contributors><titles><title>Metalearning and Recommender Systems: A literature review and empirical study on the algorithm selection problem for Collaborative Filtering</title><secondary-title>Information Sciences</secondary-title></titles><periodical><full-title>Information Sciences</full-title></periodical><pages>128-144</pages><volume>423</volume><issue>September 2018</issue><keywords><keyword>Algorithm selection</keyword><keyword>Collaborative Filtering</keyword><keyword>Metalearning</keyword><keyword>Recommendation system</keyword></keywords><dates><year>2018</year></dates><electronic-resource-num>10.1016/j.ins.2017.09.050</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Cunha, Soares, de Carvalho - 2018 - Metalearning and Recommender Systems A literature review and empirical study on the algorithm select.pdf</url></pdf-urls></urls><abstract>The problem of information overload motivated the appearance of Recommender Systems. From the several open problems in this area, the decision of which is the best recommendation algorithm for a specific problem is one of the most important and less studied. The current trend to solve this problem is the experimental evaluation of several recommendation algorithms in a handful of datasets. However, these studies require an extensive amount of computational resources, particularly processing time. To avoid these drawbacks, researchers have investigated the use of Metalearning to select the best recommendation algorithms in different scopes. Such studies allow to understand the relationships between data characteristics and the relative performance of recommendation algorithms, which can be used to select the best algorithm(s) for a new problem. The contributions of this study are two-fold: 1) to identify and discuss the key concepts of algorithm selection for recommendation algorithms via a systematic literature review and 2) to perform an experimental study on the Metalearning approaches reviewed in order to identify the most promising concepts for automatic selection of recommendation algorithms.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Bang, Jeesoo</author><author>Noh, Hyungjong</author><author>Kim, Yonghee</author><author>Lee, Gary Geunbae</author></authors></contributors><titles><title>Example-based chat-oriented dialogue system with personalized long-term memory</title><secondary-title>2015 International Conference on Big Data and Smart Computing, BIGCOMP 2015</secondary-title></titles><periodical><full-title>2015 International Conference on Big Data and Smart Computing, BIGCOMP 2015</full-title></periodical><pages>238-243</pages><keywords><keyword>Dialogue system</keyword><keyword>chatting system</keyword><keyword>conversational agent</keyword><keyword>example database</keyword><keyword>personalization</keyword></keywords><dates><year>2015</year></dates><isbn>9781479973033</isbn><electronic-resource-num>10.1109/35021BIGCOMP.2015.7072837</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Bang et al. - 2015 - Example-based chat-oriented dialogue system with personalized long-term memory.pdf</url></pdf-urls></urls><abstract>This study introduces an example-based chat-oriented dialogue system with personalization framework using long-term memory. Previous representative chat-bots use simple keyword and pattern matching methodologies. To maintain the quality of systems, generating numerous heuristic rules with human labour is inevitable. The language expert knowledge is also necessary to build those rules and matching patterns. To avoid high annotation cost, example-based dialogue management is adopted for building chat-oriented dialogue system. We also propose three features: POS-tagged tokens for sentence matching, using NE types and values for searching proper responses, and using back-off responses for unmatched user utterances. Also, our system automatically collects user-related facts from user input sentences and stores the facts into a long-term memory. System responses can be modified by applying user-related facts in the long-term memory. A relevance score of a system response is proposed to select responses that include user-related fact, or frequently used responses. In several experiments, we have found that our proposed features contribute to improve the performance and our system shows competitive performance to ALICE system with the same training corpus.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Deerwester, Scott</author><author>Dumais, Susan T.</author><author>Furnas, George W.</author><author>Landauer, Thomas K.</author><author>Harshman, Richard</author></authors></contributors><titles><title>Indexing by latent semantic analysis</title><secondary-title>Journal of the American Society for Information Science</secondary-title></titles><periodical><full-title>Journal of the American Society for Information Science</full-title></periodical><pages>391-407</pages><volume>41</volume><issue>6</issue><keywords/><dates><year>1990</year></dates><electronic-resource-num>10.1002/(SICI)1097-4571(199009)41:6&lt;391::AID-ASI1&gt;3.0.CO;2-9</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Deerwester et al. - 1990 - Indexing by latent semantic analysis.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher‐order structure in the association of terms with documents (“semantic structure”) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular‐value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo‐document vectors formed from weighted combinations of terms, and documents with supra‐threshold cosine values are returned. Initial tests find this completely automatic method for retrieval to be promising. © 1990 John Wiley &amp; Sons, Inc. Copyright © 1990 John Wiley &amp; Sons, Inc.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Paterek, Arkadiusz</author></authors></contributors><titles><title>Improving regularized singular value decomposition for collaborative filtering</title><secondary-title>Proceedings of KDD Cup and Workshop</secondary-title></titles><periodical><full-title>Proceedings of KDD Cup and Workshop</full-title></periodical><keywords/><dates><year>2007</year></dates><urls><pdf-urls><url>internal-pdf://Paterek - 2007 - Improving regularized singular value decomposition for collaborative filtering.pdf</url></pdf-urls></urls></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Koren, Yehuda</author></authors></contributors><titles><title>Factorization meets the neighborhood: a Multifaceted Collaborative Collaborative Filtering Model</title></titles><periodical/><pages>426</pages><keywords><keyword>collaborative filtering</keyword><keyword>recommender systems</keyword></keywords><dates><year>2008</year></dates><isbn>9781605581934</isbn><electronic-resource-num>10.1145/1401890.1401944</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Koren - 2008 - Factorization meets the neighborhood a Multifaceted Collaborative Collaborative Filtering Model.pdf</url></pdf-urls></urls><abstract>Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rendle, Steffen</author><author>Zhang, Li</author><author>Koren, Yehuda</author></authors></contributors><titles><title>On the Difficulty of Evaluating Baselines: A Study on Recommender Systems</title></titles><periodical/><pages>1-19</pages><keywords/><dates><year>2019</year></dates><urls><pdf-urls><url>internal-pdf://Rendle, Zhang, Koren - 2019 - On the Difficulty of Evaluating Baselines A Study on Recommender Systems.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1905.01395</url></web-urls></urls><label>Printed;Read</label><abstract>Numerical evaluations with comparisons to baselines play a central role when judging research in recommender systems. In this paper, we show that running baselines properly is difficult. We demonstrate this issue on two extensively studied datasets. First, we show that results for baselines that have been used in numerous publications over the past five years for the Movielens 10M benchmark are suboptimal. With a careful setup of a vanilla matrix factorization baseline, we are not only able to improve upon the reported results for this baseline but even outperform the reported results of any newly proposed method. Secondly, we recap the tremendous effort that was required by the community to obtain high quality results for simple methods on the Netflix Prize. Our results indicate that empirical findings in research papers are questionable unless they were obtained on standardized benchmarks where baselines have been tuned extensively by the research community.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>del Mundo, Carlo</author><author>Feng, Wu-chun</author></authors></contributors><titles><title>Enabling Efficient Intra-Warp Communication for Fourier Transforms in a Many-Core Architecture</title></titles><periodical/><keywords/><dates><year>2013</year></dates><publisher>NSF Center for High-Performance Reconfigurable Computing Virginia Tech</publisher><urls><pdf-urls><url>internal-pdf://Enabling Efficient Intra-Warp Communication for Fourier Transforms in a Many-Core Architecture.pdf</url></pdf-urls><web-urls><url>https://homes.cs.washington.edu/~cdel/papers/sc13-shuffle-abstract.pdf</url></web-urls></urls><label>CUDA;Fourier Transform;GPU;Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Varikuti, Deepthi P</author><author>Genon, Sarah</author><author>Sotiras, Aristeidis</author><author>Schwender, Holger</author><author>Hoffstaedter, Felix</author><author>Patil, Kaustubh R</author><author>Jockwitz, Christiane</author><author>Caspers, Svenja</author><author>Moebus, Susanne</author><author>Amunts, Katrin</author><author>Davatzikos, Christos</author><author>Eickhoff, Simon B</author></authors></contributors><titles><title>Evaluation of non-negative matrix factorization of grey matter in age prediction</title><secondary-title>NeuroImage</secondary-title></titles><periodical><full-title>NeuroImage</full-title></periodical><pages>394-410</pages><volume>173</volume><keywords><keyword>Age prediction</keyword><keyword>Dimensionality reduction</keyword><keyword>LASSO regression</keyword><keyword>Non-negative matrix factorization</keyword><keyword>Structural MRI</keyword><keyword>Voxel-based morphometry</keyword></keywords><dates><year>2018</year></dates><electronic-resource-num>https://doi.org/10.1016/j.neuroimage.2018.03.007</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Evaluation of non-negative matrix factorization of grey matter in age prediction.pdf</url></pdf-urls><web-urls><url>http://www.sciencedirect.com/science/article/pii/S1053811918301927</url></web-urls></urls><abstract>The relationship between grey matter volume (GMV) patterns and age can be captured by multivariate pattern analysis, allowing prediction of individuals' age based on structural imaging. Raw data, voxel-wise GMV and non-sparse factorization (with Principal Component Analysis, PCA) show good performance but do not promote relatively localized brain components for post-hoc examinations. Here we evaluated a non-negative matrix factorization (NNMF) approach to provide a reduced, but also interpretable representation of GMV data in age prediction frameworks in healthy and clinical populations. This examination was performed using three datasets: a multi-site cohort of life-span healthy adults, a single site cohort of older adults and clinical samples from the ADNI dataset with healthy subjects, participants with Mild Cognitive Impairment and patients with Alzheimer's disease (AD) subsamples. T1-weighted images were preprocessed with VBM8 standard settings to compute GMV values after normalization, segmentation and modulation for non-linear transformations only. Non-negative matrix factorization was computed on the GM voxel-wise values for a range of granularities (50–690 components) and LASSO (Least Absolute Shrinkage and Selection Operator) regression were used for age prediction. First, we compared the performance of our data compression procedure (i.e., NNMF) to various other approaches (i.e., uncompressed VBM data, PCA-based factorization and parcellation-based compression). We then investigated the impact of the granularity on the accuracy of age prediction, as well as the transferability of the factorization and model generalization across datasets. We finally validated our framework by examining age prediction in ADNI samples. Our results showed that our framework favorably compares with other approaches. They also demonstrated that the NNMF based factorization derived from one dataset could be efficiently applied to compress VBM data of another dataset and that granularities between 300 and 500 components give an optimal representation for age prediction. In addition to the good performance in healthy subjects our framework provided relatively localized brain regions as the features contributing to the prediction, thereby offering further insights into structural changes due to brain aging. Finally, our validation in clinical populations showed that our framework is sensitive to deviance from normal structural variations in pathological aging.</abstract></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Emam, S.</author><author>Du, A. X.</author><author>Surmanowicz, P.</author><author>Thomsen, S. F.</author><author>Greiner, R.</author><author>Gniadecki, R.</author></authors></contributors><titles><title>Predicting the long-term outcomes of biologics in patients with psoriasis using machine learning</title><secondary-title>British Journal of Dermatology</secondary-title></titles><periodical><full-title>British Journal of Dermatology</full-title></periodical><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1111/bjd.18741</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Emam et al. - 2019 - Predicting the long-term outcomes of biologics in patients with psoriasis using machine learning.pdf</url></pdf-urls></urls><label>Printed;Read</label></record><record><database name="My Collection.enl" path="My Collection.enl">My Collection.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Gal, Yarin</author><author>Ghahramani, Zoubin</author></authors></contributors><titles><title>Dropout as a Bayesian approximation: Representing model uncertainty in deep learning</title><secondary-title>33rd International Conference on Machine Learning, ICML 2016</secondary-title></titles><periodical><full-title>33rd International Conference on Machine Learning, ICML 2016</full-title></periodical><pages>1651-1660</pages><volume>3</volume><keywords/><dates><year>2016</year></dates><isbn>9781510829008</isbn><urls><pdf-urls><url>internal-pdf://Gal, Ghahramani - 2016 - Dropout as a Bayesian approximation Representing model uncertainty in deep learning.pdf</url></pdf-urls></urls><label>Printed;Read</label><abstract>Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs - extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.</abstract></record></records></xml>
